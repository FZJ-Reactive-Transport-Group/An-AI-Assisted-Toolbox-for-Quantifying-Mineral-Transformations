{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "import csv\n",
    "\n",
    "from stardist import random_label_cmap, _draw_polygons, fill_label_holes, relabel_image_stardist, calculate_extents, gputools_available\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "from stardist.plot import render_label, render_label_pred\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from skimage.morphology import binary_dilation\n",
    "\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddfd47",
   "metadata": {},
   "source": [
    "## Initializing StarDist 2D Model for Segmentation\n",
    "\n",
    "In this part of the script, we set up the environment for image segmentation using the StarDist 2D model. The process involves setting a random seed for reproducibility, initializing a label color map for visualization, and loading a pre-trained StarDist 2D model.\n",
    "### Steps:\n",
    "\n",
    "   - Set Random Seed:\n",
    "        A fixed random seed is set to ensure consistency in operations that involve randomness.\n",
    "\n",
    "   - Initialize Label Color Map:\n",
    "        A random label color map is created for use in visualizing segmentation results.\n",
    "\n",
    "   - Load Pre-Trained StarDist 2D Model:\n",
    "        The StarDist 2D model is instantiated and loaded from a specified directory, ready for segmentation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d454c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a random label color map for visualization\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "# Load the pre-trained StarDist 2D model\n",
    "model = StarDist2D(None, name='model name', basedir='path/to/your/model/directory')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f097e9c",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing an External Image for Segmentation\n",
    "\n",
    "This segment of the code is dedicated to loading an external image, converting it to grayscale, and inspecting its shape and data type. This is a preparatory step for image segmentation tasks, particularly when using models like StarDist 2D.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Load External Image:**\n",
    "   - The image is loaded from a specified file path using OpenCV's `cv2.imread` function.\n",
    "\n",
    "2. **Convert to Grayscale:**\n",
    "   - The loaded image is converted to grayscale format, which is a common requirement for many image processing tasks and models.\n",
    "\n",
    "3. **Inspect Image Properties:**\n",
    "   - The shape and data type of the image are inspected. This information is crucial for understanding the image's dimensions and ensuring compatibility with segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f488d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image from the specified file path\n",
    "my_img = cv2.imread(\"path/to/your/image/Image.TIFF\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "my_img = cv2.cvtColor(my_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Print the shape and data type of the image\n",
    "print(\"Image shape:\", my_img.shape)\n",
    "print(\"Image data type:\", my_img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d34243",
   "metadata": {},
   "source": [
    "## Segmenting a Normalized Image Using StarDist 2D Model\n",
    "\n",
    "This part of the script focuses on normalizing an external image and then applying the pre-trained StarDist 2D model to perform image segmentation. The normalization step is crucial for standardizing the pixel values, while the StarDist model predicts instances (segmentation) in the image.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Normalization:**\n",
    "   - The image is normalized using the `normalize` function. Normalization scales the pixel values to a specific percentile range, which is essential for consistent processing.\n",
    "   - The `axis_norm` parameter determines the axes along which the normalization is performed.\n",
    "\n",
    "2. **Segmentation with StarDist 2D:**\n",
    "   - The pre-trained StarDist 2D model is used to segment the normalized image.\n",
    "   - The `predict_instances` method performs the segmentation, returning both the segmented image and additional details.\n",
    "   - `verbose=True` enables detailed logging during the prediction process.\n",
    "   - `nms_thresh=0.1` sets the non-maximum suppression threshold, which affects the detection sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the axis for normalization\n",
    "axis_norm = (0, 1)\n",
    "\n",
    "# Normalize the image\n",
    "my_img_norm = normalize(my_img, 1, 99.8, axis=axis_norm)\n",
    "\n",
    "# Perform segmentation using the StarDist 2D model\n",
    "segmented_img, details_img = model.predict_instances(my_img_norm, verbose=True, nms_thresh=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d49c6a",
   "metadata": {},
   "source": [
    "## Visualizing the Original and Segmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38598f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the overall size of the figure\n",
    "plt.rcParams[\"figure.figsize\"] = (50, 50)\n",
    "\n",
    "# Plot the original (normalized) image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(my_img_norm, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Input Image\")\n",
    "\n",
    "# Plot the segmented image\n",
    "plt.subplot(1, 2, 2)\n",
    "# Overlay segmentation labels on the original image\n",
    "plt.imshow(render_label(segmented_img, img=my_img_norm, cmap=\"RdYlGn\", alpha=0.5))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9644b",
   "metadata": {},
   "source": [
    "## Counting Predicted Objects in Segmented Image\n",
    "\n",
    "This code snippet focuses on using the StarDist 2D model to predict segmentation labels for an image and then count the number of segmented objects within it. This is a valuable step in quantifying the results of the segmentation process.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Predict Segmentation Labels:**\n",
    "   - The `predict_instances` method of the StarDist 2D model is used to predict the segmentation labels for the normalized image.\n",
    "   \n",
    "2. **Count Objects:**\n",
    "   - The unique labels are identified, and their count is determined using `np.unique`. Each unique label represents a different object.\n",
    "   - The background label is excluded from the count (hence the subtraction of 1), ensuring that only actual objects are counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb067aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the segmentation labels for the normalized image\n",
    "labels, _ = model.predict_instances(my_img_norm)\n",
    "\n",
    "# Count the number of unique objects, excluding the background\n",
    "num_objects = len(np.unique(labels)) - 1  # Subtract 1 to exclude the background label\n",
    "\n",
    "# Print the number of predicted objects\n",
    "print(f\"Number of predicted objects: {num_objects}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4867f",
   "metadata": {},
   "source": [
    "## Rendering Segmentation Results on a Black Background\n",
    "\n",
    "This code snippet is designed to overlay the segmentation results from the StarDist model onto a black background. This approach highlights the segmented areas, making them stand out visually.\n",
    "\n",
    "### Process:\n",
    "\n",
    "- **Create a Black Background Image:**\n",
    "  - A black image (`black_img`) is created with the same dimensions as the normalized input image. This serves as the backdrop for the segmentation results.\n",
    "\n",
    "- **Overlay Segmentation Labels:**\n",
    "  - The `render_label` function overlays the segmented labels onto the black background. The labels are displayed using a specific colormap (`RdYlGn`) with a chosen level of transparency (`alpha=0.7`).\n",
    "\n",
    "- **Visualization:**\n",
    "  - The resulting image is displayed in a plot with a figure size of 6x6 inches. Axes are turned off to focus solely on the segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the segmentation results on a black background\n",
    "black_img = np.zeros_like(my_img_norm)  # Create a black image with the same shape as the normalized image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(render_label(segmented_img, img=black_img, cmap=\"RdYlGn\", alpha=0.7))  # Overlay the segmented labels on the black image\n",
    "plt.axis('off')  # Hide the axes for a cleaner presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5196cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand detected regions to excapsulate the crystals completely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe32ea",
   "metadata": {},
   "source": [
    "## Expanding Segmentation Mask and Rendering on Image\n",
    "\n",
    "This code snippet involves expanding the segmentation mask obtained from the StarDist model and then rendering it onto the original image for visual examination. \n",
    "\n",
    "1. **Expand Segmentation Mask:**\n",
    "   - Using `binary_dilation` to expand the segmented mask. This enlarges the segmented areas for better visibility.\n",
    "   - A footprint (structuring element) with a shape of `(30, 30)` defines how the dilation is applied.\n",
    "\n",
    "2. **Rendering Expanded Mask on Original Image:**\n",
    "   - The `render_label` function overlays the expanded mask onto the original image.\n",
    "   - The 'RdYlGn' colormap is used with an alpha value of 0.7, providing a clear and distinct visualization of the expanded mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c90022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform binary dilation on the segmented mask to expand the segmented areas\n",
    "expanded_mask = binary_dilation(segmented_img, footprint=np.ones((30, 30)))\n",
    "\n",
    "# Set up the figure for visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Overlay the expanded mask on the original image and display\n",
    "plt.imshow(render_label(expanded_mask, img=my_img_norm, cmap=\"RdYlGn\", alpha=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep the region from the original image that matched the expanded predicted region and render the rest \n",
    "# of the image as white, I used the expanded mask as a boolean index to select the pixels in the original \n",
    "# image that belong to the predicted region, and set the remaining pixels to white"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183741e",
   "metadata": {},
   "source": [
    "## Cropping Expanded Regions from Segmented Image\n",
    "\n",
    "This code snippet demonstrates the process of isolating the expanded regions from a segmented image. The expanded mask is used to selectively keep the regions of interest from the original image while setting the remaining areas to white. This approach highlights the segmented areas, effectively cropping them out from the rest of the image.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Create a Copy of the Original Image:**\n",
    "   - The original image is copied to retain its original state while allowing modifications on the copy.\n",
    "\n",
    "2. **Apply Expanded Mask to Image:**\n",
    "   - The expanded mask is used as a boolean index to select pixels in the original image that belong to the predicted region.\n",
    "   - Pixels not in the predicted region are set to white, diminishing their visual impact.\n",
    "\n",
    "3. **Visualize the Cropped Image:**\n",
    "   - A new figure is created for displaying the results.\n",
    "   - The `render_label` function overlays the expanded mask on a black background image, clearly marking the segmented areas.\n",
    "   - The cropped image is then displayed, showing the segmented areas in their original form against a white background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping the expanded regions from the segmented image\n",
    "# and rendering the rest of the image as white\n",
    "\n",
    "# Copy the original normalized image\n",
    "my_img_cropped = my_img_norm.copy()\n",
    "\n",
    "# Using the expanded mask as a boolean index, keep the pixels in the original image that belong to the predicted region.\n",
    "# Set the remaining pixels to white (value of 1.0)\n",
    "my_img_cropped[~expanded_mask] = 1.0\n",
    "\n",
    "# Setting up the figure for visualization\n",
    "plt.figure(figsize=(10,8))\n",
    "black_img = np.zeros_like(my_img_norm)\n",
    "\n",
    "# Overlay the expanded mask on the black image for clear visualization of the segmented areas\n",
    "render_label(expanded_mask, img=black_img, cmap=\"RdYlGn\", alpha=0.7)\n",
    "\n",
    "# Display the cropped image where the segmented regions are highlighted and the rest of the image is dimmed\n",
    "plt.imshow(my_img_cropped, cmap=\"gray\", alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ec287",
   "metadata": {},
   "source": [
    "## Creating a Binary Mask from the Expanded Segmented Regions\n",
    "\n",
    "This code snippet focuses on creating a binary mask from the expanded segmented regions of an image. The process involves modifying a copy of the normalized image to highlight the segmented areas and then converting it into a binary image using a specified threshold.\n",
    "\n",
    "### Process:\n",
    "\n",
    "1. **Copy and Modify the Original Image:**\n",
    "   - A copy of the normalized image is created.\n",
    "   - The expanded mask is applied to this copy. Pixels in the segmented regions are kept as they are, while the others are set to black (value of 0), and then subsequently to white (value of 1).\n",
    "\n",
    "2. **Threshold Application:**\n",
    "   - A threshold value is defined to distinguish the foreground from the background in the image.\n",
    "   - The image is converted into a binary format (black and white) based on this threshold, resulting in a binary mask.\n",
    "\n",
    "3. **Visualizing the Binary Mask:**\n",
    "   - The binary mask is visualized in grayscale to clearly show the segmented regions against the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the normalized image\n",
    "masked_img = np.copy(my_img_norm)\n",
    "\n",
    "# Apply the expanded mask to the image copy, setting non-segmented regions to black and then to white\n",
    "masked_img[~expanded_mask] = 0  # Set non-segmented regions to 0 (black)\n",
    "masked_img[~expanded_mask] = 1  # Set non-segmented regions to 1 (white)\n",
    "\n",
    "# Define a threshold value to differentiate the foreground from the background\n",
    "threshold_value = 0.5\n",
    "\n",
    "# Convert the masked image to a binary image based on the threshold\n",
    "binary_img = (masked_img > threshold_value).astype(np.uint8)\n",
    "\n",
    "# Set up the figure for visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Display the binary image to visualize the mask\n",
    "plt.imshow(binary_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91c042",
   "metadata": {},
   "source": [
    "## Analyzing Contours and Calculating Circularity\n",
    "\n",
    "This code snippet involves finding contours in a binary image, calculating the circularity and size of each contour, and labeling them. The aim is to analyze the shapes of segmented regions and quantify their circularity.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Find Contours:**\n",
    "   - Using OpenCV's `cv2.findContours` method, contours within the binary image are detected. These contours represent the edges of the segmented regions.\n",
    "\n",
    "2. **Calculate Circularity and Size:**\n",
    "   - For each contour, its area and perimeter are calculated. Using these, the circularity is determined, which is a measure of how close the shape is to a perfect circle.\n",
    "\n",
    "3. **Filter Contours Based on Area:**\n",
    "   - Only contours within a specified area range are considered to filter out too small or too large regions.\n",
    "\n",
    "4. **Draw and Label Contours:**\n",
    "   - Each valid contour is drawn and labeled with a number on a separate image for visualization.\n",
    "\n",
    "5. **Create Data Table:**\n",
    "   - A table is constructed to store the circularity and size data for each contour. This data can be further analyzed or saved.\n",
    "\n",
    "6. **Save Data as CSV (Optional):**\n",
    "   - The data table is converted into a pandas DataFrame and can be saved as a CSV file for external analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf81b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contours in the binary image\n",
    "contours, hierarchy = cv2.findContours(binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Initialize an image to draw contours\n",
    "img_contours = np.zeros_like(binary_img)\n",
    "img_contours.fill(255)  # Fill with white background\n",
    "\n",
    "# Initialize a list to store data for each contour\n",
    "table_data = []\n",
    "\n",
    "# Loop through each contour to calculate circularity and size\n",
    "for i, contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    # Filter out contours that are too small or too large\n",
    "    if area < 50 or area > 3000:\n",
    "        continue\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    if perimeter == 0:\n",
    "        continue\n",
    "    circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "\n",
    "    # Draw filled contours on the image\n",
    "    cv2.drawContours(img_contours, contours, i, (0, 0, 0), thickness=1, lineType=cv2.LINE_AA)\n",
    "    cv2.drawContours(img_contours, contours, i, (0, 0, 0), thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Label each contour with a number\n",
    "    cv2.putText(img_contours, str(i), (contour[0][0][0]+20, contour[0][0][1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), thickness=2)\n",
    "    \n",
    "    # Append contour data to the table\n",
    "    table_data.append({'Contour': i, 'Circularity': circularity, 'Size': area})\n",
    "\n",
    "# Convert the table data into a pandas DataFrame\n",
    "df = pd.DataFrame(table_data)\n",
    "# Optional: Save the data to a CSV file\n",
    "# df.to_csv('circularities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46256496",
   "metadata": {},
   "source": [
    "## Displaying Segmentation Analysis Results\n",
    "\n",
    "This code snippet is aimed at presenting the results of the segmentation analysis. It involves displaying the total count of detected cells (contours) and the details of each cell, including its circularity and size.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Count Detected Cells:**\n",
    "   - The total number of cells detected in the segmentation analysis is determined by counting the entries in the DataFrame (`df`).\n",
    "\n",
    "2. **Print the Total Count:**\n",
    "   - The total count of detected cells is printed out for quick reference.\n",
    "\n",
    "3. **Display Detailed Analysis:**\n",
    "   - The DataFrame containing the analysis details for each cell, such as circularity and size, is printed.\n",
    "   - Optionally, only the top entries of the DataFrame can be displayed for a concise summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3209cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the number of cells (contours) detected\n",
    "print(\"Number of cells detected:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b05669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the entire DataFrame to show the analysis results for each cell\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Optional: Print only the top 10 entries of the DataFrame for a concise summary\n",
    "# print(df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_contours, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cd80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
