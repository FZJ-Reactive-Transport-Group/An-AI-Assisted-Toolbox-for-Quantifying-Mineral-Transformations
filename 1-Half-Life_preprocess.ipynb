{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ce7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code block imports essential libraries. No changes are required here \n",
    "# for new users unless additional functionality is needed.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil",
    "from tifffile import imread\n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8df13e-8fca-4840-9b2c-717e0dc931d3",
   "metadata": {},
   "source": [
    "The (find_tiff_images) function scans a specified main folder and its subfolders to locate all .tiff and .tif image files, returning a list of their paths. Simply input the path to your main folder as the argument to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dab87f-cb55-4b79-bb4e-547502852b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tiff_images(main_folder):\n",
    "    # Define the patterns to search for\n",
    "    patterns = ['*.tiff', '*.tif']\n",
    "\n",
    "    # List to store found image paths\n",
    "    found_images = []\n",
    "\n",
    "    # Walk through the directory\n",
    "    for dirpath, dirnames, filenames in os.walk(main_folder):\n",
    "        for pattern in patterns:\n",
    "            # Construct the full pattern path\n",
    "            full_pattern = os.path.join(dirpath, pattern)\n",
    "            # Find matches and extend the list of found images\n",
    "            found_images.extend(glob.glob(full_pattern))\n",
    "\n",
    "    return found_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0ae5f-58d7-4834-801a-a47512b62832",
   "metadata": {},
   "source": [
    "The (create_output_structure) function replicates the folder structure of a given input directory into a specified output directory. Use this to maintain a consistent directory structure for processed images or outputs, matching the organization of your input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c99c88-158f-4d0e-bb6d-549a5be13e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_structure(input_folder, output_folder):\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for subdir, dirs, files in os.walk(input_folder):\n",
    "        # Create a corresponding subdirectory structure in the output folder\n",
    "        for dir in dirs:\n",
    "            source_dir = os.path.join(subdir, dir)\n",
    "            dest_dir = source_dir.replace(input_folder, output_folder)\n",
    "            if not os.path.exists(dest_dir):\n",
    "                os.makedirs(dest_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e88a2f-dfe0-405f-b7af-126ec84bd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images from specified folder path\n",
    "\n",
    "# Specifying the path to the Excel file. This file is expected to be created by a separate script named '1_cropping_desired_crystal_coordinates.ipynb'.\n",
    "input_folder = 'path/to/microfluidic_data'\n",
    "image_paths = find_tiff_images(input_folder)\n",
    "output_folder = 'path/to/output_data'\n",
    "create_output_structure(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60de6a0",
   "metadata": {},
   "source": [
    "This code block performs advanced image pre-processing, crucial for preparing images for training in a Convolutional Neural Network (CNN), specifically for applications like crystal identification. Each step in the process is designed to enhance certain features of the images and suppress noise, making them more suitable for pattern recognition by a CNN.\r\n",
    "\r\n",
    "Overview of Techniques Used:\r\n",
    "### Bilateral Filter (cv2.bilateralFilter):\r\n",
    "\r\n",
    "#### Purpose: Reduces noise while preserving edges.\r\n",
    "#### Parameters:\r\n",
    "- Diameter of Pixel Neighborhood (9): Affects the size of the area considered for filtering.\r\n",
    "- Filter Sigma in Color Space (75): Controls the extent to which differences in color will be considered noise.\r\n",
    "- Filter Sigma in Coordinate Space (75): Influences how far the filter searches for similarities in pixel values.\r\n",
    "- Adjustments: Modify these parameters to balance between noise reduction and edge preservation.\r\n",
    "### Non-Local Means Denoising (cv2.fastNlMeansDenoising):\r\n",
    "\r\n",
    "#### Purpose: Further reduces noise from the image.\r\n",
    "#### Parameters:\r\n",
    "- Filter Strength (h=21): Determines how much noise to remove. Higher values remove more noise but can blur details.\r\n",
    "- Template Window Size (16): Size of the window used to examine the similarity of pixels.\r\n",
    "- Search Window Size (19): Size of the window used to search for pixels for denoising.\r\n",
    "- Adjustments: Tweak these for different levels of denoising, considering the balance between noise reduction and detail preservation.\r\n",
    "### Grayscale Conversion (cv2.cvtColor):\r\n",
    "\r\n",
    "Converts the image to grayscale, reducing complexity for the following thresholding step.\r\n",
    "### Adaptive Thresholding (cv2.adaptiveThreshold):\r\n",
    "\r\n",
    "#### Purpose: Converts the grayscale image to a binary image, enhancing features.\r\n",
    "#### Parameters:\r\n",
    "- Block Size (15): Determines the size of the neighborhood used to calculate the threshold value.\r\n",
    "- Constant Subtracted from Mean (3): Fine-tunes the threshold value.\r\n",
    "- Adjustments: Change these values to optimize the binarization effect, which is crucial for highlighting features against the background.\r\n",
    "### Sharpening:\r\n",
    "\r\n",
    "#### Purpose: Enhances the edges and details in the binary image.\r\n",
    "#### Method: Uses a sharpening kernel to accentuate edges.\r\n",
    "### Laplacian Operator (cv2.Laplacian):\r\n",
    "\r\n",
    "#### Purpose: Highlights regions of rapid intensity change, enhancing edges and textures.\r\n",
    "Conversion: The result is converted to an 8-bit absolute value to ensure compatibility with image formats.\r\n",
    "### Saving Processed Images:\r\n",
    "\r\n",
    "The processed images are saved in the specified output_folder, retaining the original filenames.\r\n",
    "Note on Usage:\r\n",
    "It's essential to adjust the parameters according to your specific dataset and the features you wish to emphasize.\r\n",
    "These adjustments can significantly impact the effectiveness of the CNN in recognizing patterns and identifying crystals.\r\n",
    "This comprehensive pre-processing pipeline is tailored to enhance critical features in microfluidic images, facilitating more accurate and efficient CNN training for crystal identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246f2de-50e1-4362-8be5-19d6ecfbd132",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in image_paths:\n",
    "    # Read the image in grayscale mode\n",
    "    img = cv2.imread(image_path, 0)\n",
    "    # Convert the grayscale image to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Apply bilateral filter\n",
    "    img_DN = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "    img_DN_2 = cv2.fastNlMeansDenoising(img_DN, None, h=21, templateWindowSize=16, searchWindowSize=19)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img_DN_2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 3)\n",
    "\n",
    "    # Sharpening kernel\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1, 9, -1],\n",
    "                       [-1, -1, -1]])\n",
    "\n",
    "    # Apply the kernel to sharpen\n",
    "    sharpened = cv2.filter2D(thresh, -1, kernel)\n",
    "\n",
    "    # Apply Laplacian\n",
    "    laplacian = cv2.Laplacian(sharpened, cv2.CV_64F)\n",
    "    laplacian_abs = cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "    # Construct the output path and save the image\n",
    "    output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_folder, laplacian_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47699f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
